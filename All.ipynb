{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e34aee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6371137b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>mark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>—Å–ø–∞—Å–∏–±–æ –±–ª–æ–∫–∏—Ä–æ–≤–∫–µ –∏–Ω—Å—Ç–∞–≥—Ä–∞–º–∞)))</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–°–∞–Ω–∫—Ü–∏–∏ –∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –æ—Ç –†–ö–ù –∫–æ–º—É —Ç–æ –≤ –ø–ª—é—Å, –∫–æ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–ª—é–±–ª—é –≤–∫, –Ω–æ —ç—Ç–æ –Ω–µ –≤–∞—à–∞ –∑–∞—Å–ª—É–≥–∞</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>–ü—É—à–∫–∞ üî•üî•üî• –°–ø–∞—Å–∏–±–æ, –ª—é–±–∏–º—ã–π –í–ö ‚ù§</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–ù—É —Ç–∞–∫, –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–æ–≤ –∏ —Ç.–¥ = –≤–∞—à–∞ –≤...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>https://vk.com/audios627992484?section=all&amp;z=a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>–ò–Ω—Ç–µ—Ä–µ—Å–Ω–µ–Ω—å–∫–æ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>–ê–¥–æ–≤—ã–π –∫–æ–ª—Ö–æ–∑</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>–ú—É–∑—ã–∫–∞ –Ω–µ –∏–≥—Ä–∞–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç –¥–µ–Ω—å–≥–∏ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text mark\n",
       "0                     —Å–ø–∞—Å–∏–±–æ –±–ª–æ–∫–∏—Ä–æ–≤–∫–µ –∏–Ω—Å—Ç–∞–≥—Ä–∞–º–∞)))    0\n",
       "1    –°–∞–Ω–∫—Ü–∏–∏ –∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –æ—Ç –†–ö–ù –∫–æ–º—É —Ç–æ –≤ –ø–ª—é—Å, –∫–æ...    0\n",
       "2                     –ª—é–±–ª—é –≤–∫, –Ω–æ —ç—Ç–æ –Ω–µ –≤–∞—à–∞ –∑–∞—Å–ª—É–≥–∞    0\n",
       "3                      –ü—É—à–∫–∞ üî•üî•üî• –°–ø–∞—Å–∏–±–æ, –ª—é–±–∏–º—ã–π –í–ö ‚ù§    0\n",
       "4    –ù—É —Ç–∞–∫, –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–æ–≤ –∏ —Ç.–¥ = –≤–∞—à–∞ –≤...    0\n",
       "..                                                 ...  ...\n",
       "219  https://vk.com/audios627992484?section=all&z=a...    0\n",
       "220                                                       0\n",
       "221                                      –ò–Ω—Ç–µ—Ä–µ—Å–Ω–µ–Ω—å–∫–æ    0\n",
       "222                                      –ê–¥–æ–≤—ã–π –∫–æ–ª—Ö–æ–∑    0\n",
       "223  –ú—É–∑—ã–∫–∞ –Ω–µ –∏–≥—Ä–∞–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç –¥–µ–Ω—å–≥–∏ ...    0\n",
       "\n",
       "[224 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class PostDefinition:\n",
    "    owner_id: str\n",
    "    post_id: str\n",
    "\n",
    "POSTS_TO_CHECK = [\n",
    "    PostDefinition('-22822305', '1297486'),\n",
    "    PostDefinition('-26062647', '893415'), \n",
    "    PostDefinition('-147845620', '423323'), \n",
    "]\n",
    "\n",
    "import vk_api\n",
    "\n",
    "def get_members(groupid): \n",
    "  pass\n",
    "\n",
    "def save_data(data, filename=\"data.txt\"):  \n",
    "  pass\n",
    " \n",
    "token = \"02b817b802b817b802b817b8aa02c46b7e002b802b817b860cbbf26b6f94cc3c68f69e2\" \n",
    "v = 5.92\n",
    "vk_session = vk_api.VkApi(token=token)\n",
    "vk = vk_session.get_api() \n",
    "    \n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(columns=['text', 'mark'])\n",
    "\n",
    "for post in POSTS_TO_CHECK:\n",
    "    resp = vk.wall.getComments(owner_id=post.owner_id, post_id=post.post_id, need_likes=0, count=100, extended=0)\n",
    "    items = resp['items']\n",
    "   \n",
    "    for item in items:\n",
    "        text = item['text']\n",
    "        df = df.append({'text': text, 'mark': 0}, ignore_index=True)\n",
    "        \n",
    "df.to_csv('KZcorp.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3ef5160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>text</th>\n",
       "      <th>mark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>–°–∏—Ä–∏—è–¥–∞ –±–æ–ª—ã–ø –∂–∞—Ç“õ–∞–Ω —Å–æ“ì—ã—Å –¥“±—Ä—ã—Å —Å–æ“ì—ã—Å –∫–∞–ø—ñ—Ä–ª–µ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>–ë—ñ—Ä–µ—É–≥–µ–¥—ñ–Ω –∫”©–Ω—ñ–ª—ñ–Ω–µ  –∫“Ø–ª–∫—ñ –±—ñ–ª–µ—É—ñ–Ω–µ –º“±“£ “±—è–ª–∞—Ç–∞...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8–∂—ã–ª –∫–æ—Ä—à–∏—Å–∏ —Å–æ–ª –±–∞—è–≥—ã —Ö–∞–ª–∞—Ç–ø–µ–Ω –∂—É—Ä)))</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>–û–∏ –∫–µ—à–∏—Ä–∏–Ω–∏–∑–¥–µ—Ä –∞–±–∞–∏–ª–∞–Ω—ã–∑–¥–∞—Ä</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>–ê–±–∞–∏–ª–∞</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>–°–∞“õ–∞–ª–¥—ã–ª–∞—Ä –º–µ–Ω —Ö–∏–¥–∂–∞–ø —Ç–∞“ì—ã–ª–∞—Ä  –∞–¥–∞—Å“õ–∞–Ω–¥–∞ —Å–∞“õ–∞–ª...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>–Ω–µ —É–≤–ª–µ–∫–∞–π—Ç–µ—Å—å –ø–∞—Ü–∞–Ω—ã , —ç—Ç–æ –Ω–µ –∏–≥—Ä—É—à–∫–∏</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>–ê–ª–ª–∞ —Å–∞–∫—Ç–∞—Å—ã–Ω! –∂—É–º–∞–∫—Ç—ã–Ω –∫–∏–ª—Ç–∏ –∞–Ω–∞–Ω—ã–Ω –∞—è–≥—ã–Ω—ã–Ω –∞...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>–∫–∞–∑–∞–∫ –∂–∞—Å—Ç–∞—Ä—ã .))) –∫–∞–∑–∞–∫ –µ–ªi–Ωi–Ω –±–æ–ª–∞—à–∞–≥—ã –µ–∫–µ–Ωi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>–¥“±—Ä—ã—Å –æ—Å—ã–Ω–¥–∞–π–¥—ã“£ –∞–ª–¥—ã–Ω –∞–ª—É –∫–µ—Ä–µ–∫</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  Unnamed: 0.1  \\\n",
       "0           0.0           0.0   \n",
       "1           1.0           1.0   \n",
       "2           2.0           2.0   \n",
       "3           3.0           3.0   \n",
       "4           4.0           4.0   \n",
       "..          ...           ...   \n",
       "112         NaN           NaN   \n",
       "113         NaN           NaN   \n",
       "114         NaN           NaN   \n",
       "115         NaN           NaN   \n",
       "116         NaN           NaN   \n",
       "\n",
       "                                                  text  mark  \n",
       "0    –°–∏—Ä–∏—è–¥–∞ –±–æ–ª—ã–ø –∂–∞—Ç“õ–∞–Ω —Å–æ“ì—ã—Å –¥“±—Ä—ã—Å —Å–æ“ì—ã—Å –∫–∞–ø—ñ—Ä–ª–µ...     0  \n",
       "1    –ë—ñ—Ä–µ—É–≥–µ–¥—ñ–Ω –∫”©–Ω—ñ–ª—ñ–Ω–µ  –∫“Ø–ª–∫—ñ –±—ñ–ª–µ—É—ñ–Ω–µ –º“±“£ “±—è–ª–∞—Ç–∞...     0  \n",
       "2               8–∂—ã–ª –∫–æ—Ä—à–∏—Å–∏ —Å–æ–ª –±–∞—è–≥—ã —Ö–∞–ª–∞—Ç–ø–µ–Ω –∂—É—Ä)))     0  \n",
       "3                         –û–∏ –∫–µ—à–∏—Ä–∏–Ω–∏–∑–¥–µ—Ä –∞–±–∞–∏–ª–∞–Ω—ã–∑–¥–∞—Ä     0  \n",
       "4                                               –ê–±–∞–∏–ª–∞     0  \n",
       "..                                                 ...   ...  \n",
       "112  –°–∞“õ–∞–ª–¥—ã–ª–∞—Ä –º–µ–Ω —Ö–∏–¥–∂–∞–ø —Ç–∞“ì—ã–ª–∞—Ä  –∞–¥–∞—Å“õ–∞–Ω–¥–∞ —Å–∞“õ–∞–ª...     0  \n",
       "113             –Ω–µ —É–≤–ª–µ–∫–∞–π—Ç–µ—Å—å –ø–∞—Ü–∞–Ω—ã , —ç—Ç–æ –Ω–µ –∏–≥—Ä—É—à–∫–∏     0  \n",
       "114  –ê–ª–ª–∞ —Å–∞–∫—Ç–∞—Å—ã–Ω! –∂—É–º–∞–∫—Ç—ã–Ω –∫–∏–ª—Ç–∏ –∞–Ω–∞–Ω—ã–Ω –∞—è–≥—ã–Ω—ã–Ω –∞...     0  \n",
       "115  –∫–∞–∑–∞–∫ –∂–∞—Å—Ç–∞—Ä—ã .))) –∫–∞–∑–∞–∫ –µ–ªi–Ωi–Ω –±–æ–ª–∞—à–∞–≥—ã –µ–∫–µ–Ωi...     0  \n",
       "116                   –¥“±—Ä—ã—Å –æ—Å—ã–Ω–¥–∞–π–¥—ã“£ –∞–ª–¥—ã–Ω –∞–ª—É –∫–µ—Ä–µ–∫     0  \n",
       "\n",
       "[117 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"KZcorpYouTube-2.csv\", index_col=False)\n",
    "\n",
    "api_key =\"AIzaSyC7f4CZv7Neg84r1ilcvxXGK7eq8KJ_puk\"\n",
    "video_id= \"3VvIc3LXXZU\"\n",
    "\n",
    "resource = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "request = resource. commentThreads().list(\n",
    "                            part=\"snippet\",\n",
    "                            maxResults= 300,\n",
    "                            videoId=video_id\n",
    "                            )  \n",
    "\n",
    "response =request.execute()\n",
    "items = response[\"items\"][:300]\n",
    "\n",
    "print(\"------------------------------------------------------------------------------------------------------\")\n",
    "for item in items:\n",
    "    item_info = item[\"snippet\"]\n",
    "    \n",
    "   \n",
    "    topLevelComment = item_info[\"topLevelComment\"]\n",
    "    comment_info = topLevelComment[\"snippet\"]\n",
    "    df = df.append({'text': comment_info[\"textDisplay\"], 'mark': 0}, ignore_index=True)\n",
    " \n",
    "df = df.reset_index(drop=True)\n",
    "df.drop_duplicates()\n",
    "df.to_csv('KZcorpYouTube-2.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea40a907",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df1 = pd.read_csv(\"corpus.csv\", index_col=False)\n",
    "\n",
    "def file_to_list(file):\n",
    "    rtn: object = []\n",
    "    file_object: object = open(file, \"r\")\n",
    "    rtn: object = file_object.read().splitlines()\n",
    "    file_object.close()\n",
    "    return list(filter(None, pd.unique(rtn ).tolist())) \n",
    "    pass\n",
    "\n",
    "def file_to_list_for_affix(file):\n",
    "    rtn: object = []\n",
    "    file_object: object = open(file, \"r\")\n",
    "    rtn: object = file_object.read().replace(\" \", \"\").splitlines()\n",
    "    file_object.close()\n",
    "    return list(filter(None, pd.unique(rtn ).tolist())) \n",
    "    pass\n",
    "\n",
    "data_from_file: object = file_to_list('stopWordsKaz.txt') \n",
    "sufixes1 = file_to_list_for_affix('affix.txt') \n",
    "\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'[^\\w]', ' ', text)\n",
    "    return text\n",
    "    \n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in data_from_file])\n",
    "\n",
    "def removeWord(text):\n",
    "    # print(text + \"\\n\")\n",
    "    result = text\n",
    "    lemax = 8\n",
    "    ew = \"\"\n",
    "    ok = 1\n",
    "\n",
    "    if len(result) <= 5:\n",
    "        ew = result[len(result) - 1 : len(result)]\n",
    "        ok = 2\n",
    "\n",
    "    lw = len(text)\n",
    "    lew = len(text) - 2\n",
    "\n",
    "    \n",
    "    lewmax = lw - 2\n",
    "  \n",
    "    if lw <= lemax:\n",
    "        lew = lewmax\n",
    "    else:\n",
    "        lew = lemax\n",
    "        ew = result[len(text) - ok]\n",
    "    \n",
    "    while True:\n",
    "        if sufixes1.__contains__(ew):\n",
    "            i = len(ew)\n",
    "            result = result[0 : len(result) - ok + 1]\n",
    "            ok = 1\n",
    "        else:\n",
    "            lew = lew - 1\n",
    "\n",
    "        if lew >= 1:\n",
    "            ew = result[len(result) - ok: len(result)]\n",
    "            ok = ok + 1\n",
    "        else: break\n",
    "    return result\n",
    "\n",
    "def cleanWords(text):\n",
    "\n",
    "    text = text.split()\n",
    "    s = \"\"\n",
    "    for t in text:\n",
    "        s += removeWord(t) + \" \"\n",
    "    return s\n",
    "    \n",
    "    # print(\"Input: \" + text + \"   Output: \" + result)\n",
    "\n",
    "# text = \"–û“õ—É—à—ã–ª–∞—Ä–¥–∞–Ω –ø–∞—Ä—Ç–∞–¥—ã –∞–ª–º–∞–ª–∞—Ä–¥—ã —Å”©–º–∫–µ–ª–µ—Ä–¥–µ–Ω —Å”©–º–∫–µ–ª–µ—Ä–¥—ñ —Å–æ—Ç–∫–∞–ª–∞—Ä–¥—ã –±–∞–∫–ø–µ–Ω –±–∞–∫—Ç–∞–Ω —É–π–≥–µ\"\n",
    "    \n",
    "# textArr = text.split(\" \")\n",
    "\n",
    "# for t in textArr:\n",
    "#     cleanWords(t)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19e78778",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove Stopwords: complete\n",
      "Clean Text: complete\n",
      "Clean Words: complete\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>metka</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“ö–∞–∑–∞“õ—Å—Ç–∞–Ω–¥—ã –±“±–∑—ã–ø –∂–∞—Ç—ã—Ä“ì–∞–Ω–¥–∞—Ä: –ï—Ä—Å—ñ–Ω ”ò–º—ñ—Ä–µ, –ê–±...</td>\n",
       "      <td>1</td>\n",
       "      <td>“õ–∞–∑–∞“õ—Å—Ç –±“±–∑ –∂–∞—Ç—ã—Ä“ì –µ—Ä—Å ”ô–º—ñ—Ä–µ –∞–±–¥“±“ì–∞–ø–ø–∞—Ä –∞—Ä–º “õ—É...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>–¢–∞–ª—ñ–ø—Ç–µ—Ä –ê–ª“ì–∞ –î—ñ–Ω—Å—ñ–∑–¥–µ—Ä–¥—ñ –ê–ª–ª–∞–Ω—ã“£ –ø–∞—Ä—ã–∑ –±–æ–ª“ì–∞–Ω...</td>\n",
       "      <td>1</td>\n",
       "      <td>—Ç–∞–ª –∞–ª –¥ –∞–ª–ª–∞–Ω—ã“£ –ø–∞—Ä—ã–∑ –±–æ–ª“ì –∂“Ø–∑ ”©–≥—ñ—Ä–≥ “õ“±—Ä—Ç—É –∫–µ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>–ê—Ç—É –∫–µ—Ä–µ–∫ —Ç–∞–º—ã—Ä—ã–º–µ–Ω –∂–æ–π—ã–ª“ì–∞–Ω–¥–∞–π! https://www.y...</td>\n",
       "      <td>1</td>\n",
       "      <td>–∞—Ç—É –∫–µ—Ä–µ–∫ —Ç–∞–º—ã—Ä—ã–º –∂–æ–π—ã–ª“ì</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>—Å–æ“ì—ã—Å –±–æ–ª—Å–∞ –±–æ–ª—Å—ã–Ω,–∂–µ–º“õ–æ—Ä –π—Ç—Ç–µ—Ä–¥—ñ “õ—É—ã–ø –∂—É—Ä—ñ–ø ”©...</td>\n",
       "      <td>1</td>\n",
       "      <td>—Å–æ“ì—ã—Å –±–æ–ª—Å–∞ –±–æ–ª—Å –∂–µ–º“õ–æ—Ä –π—Ç “õ—É –∂—É—Ä ”©–ª—Ç—ñ—Ä–µ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>–¢–∞–ª–∏–±—Ç–µ—Ä–¥—ñ“£ “Ø—Å—Ç—ñ–Ω–µ–Ω –±–æ–º–±–∞ —Ç–∞—Å—Ç–∞–ø –∂–æ–∫ –∫—ã–ª—ã–ø –∂—ñ–±...</td>\n",
       "      <td>1</td>\n",
       "      <td>—Ç–∞–ª–∏–± “Ø—Å—Ç –±–æ–º —Ç–∞—Å—Ç–∞–ø –∂–æ–∫ –∫—ã–ª –∂—ñ–±–µ—Ä–µ—Ç—ñ–Ω–≥–æ –±—É–ª –∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5931</th>\n",
       "      <td>–º–∞—Å–æ–Ω–¥—ã“õ “Ø–π–¥–µ–Ω —à—ã“õ“õ–∞–Ω –±“±–ª –∞–¥–∞–º–¥–∞—Ä ”©–∑–¥–µ—Ä—ñ–Ω—ñ“£ —Å—ã...</td>\n",
       "      <td>1</td>\n",
       "      <td>–º–∞—Å–æ–Ω “Ø–π–¥ —à—ã“õ“õ –∞–¥–∞–º ”©–∑–¥–µ—Ä—ñ–Ω—ñ“£ —Å—ã–π–∞“õ—ã “õ–∞–ª–∞–π –∞–ª–∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>–ù–µ–≥–µ —Å–µ–Ω—É—à—ñ–ª–µ—Ä–¥—ñ“£ —Å–µ–∑—ñ–º–¥–µ—Ä—ñ–Ω “õ–æ—Ä–ª–∞—É“ì–∞ –±–æ–ª–º–∞–π–¥—ã...</td>\n",
       "      <td>1</td>\n",
       "      <td>–Ω–µ —Å–µ–Ω—É —Å–µ–∑—ñ–º “õ–æ—Ä–ª–∞—É –±–æ–ª–º–∞–π –∞—Ç–µ–∏—Å —Å–µ–∑—ñ–º “õ–æ—Ä–ª–∞—É...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>–®—ã–Ω –º”ô–Ω—ñ–Ω–¥–µ, –∞—Ç–µ–∏—Å—Ç–µ—Ä –¥—ñ–Ω–¥–∞—Ä–ª–∞—Ä–¥—ã“£ ”©–∑–¥–µ—Ä—ñ–Ω–µ “õ–∞...</td>\n",
       "      <td>1</td>\n",
       "      <td>—à—ã–Ω –º”ô–Ω –∞—Ç–µ–∏—Å –¥—ñ–Ω ”©–∑–¥–µ—Ä—ñ “õ–∞—Ä–∞“ì –¥—ñ–Ω –∫”©–±—ñ—Ä–µ–∫ –±—ñ–ª...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>–ö–∏–µ–ª—ñ –∫—ñ—Ç–∞–ø—Ç–∞ –∫—Ä–µ—Å—Ç—Ç–µ—Ä —Ç—É—Ä–∞–ª—ã –µ—à—Ç–µ“£–µ –∞–π—Ç—ã–ª–º–∞“ì–∞...</td>\n",
       "      <td>1</td>\n",
       "      <td>–∫–∏–µ –∫—ñ—Ç–∞–ø –∫—Ä–µ—Å—Ç –µ—à—Ç–µ“£–µ –∞–π—Ç—ã–ª–º–∞“ì “õ–∞—Å–∏–µ—Ç —Å—É —à–æ–º—ã...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5935</th>\n",
       "      <td>”®–ª–≥–µ–Ω—à–µ ”ô—Ä–±—ñ—Ä “õ–∞–∑–∞“õ –∞–∑–∞–º–∞—Ç—ã –∂”ô–Ω–µ –∞–∑–∞–º–∞—Ç—à–∞—Å—ã –µ–ª...</td>\n",
       "      <td>1</td>\n",
       "      <td>”©–ª–≥–µ–Ω—à–µ “õ–∞–∑–∞“õ –∞–∑–∞ –∂”ô –∞–∑–∞–º–∞—Ç—à–∞—Å—ã –µ–ª “õ–æ—Ä“ì–∞–π –µ—à–∫—ñ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5936 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  metka  \\\n",
       "0     “ö–∞–∑–∞“õ—Å—Ç–∞–Ω–¥—ã –±“±–∑—ã–ø –∂–∞—Ç—ã—Ä“ì–∞–Ω–¥–∞—Ä: –ï—Ä—Å—ñ–Ω ”ò–º—ñ—Ä–µ, –ê–±...      1   \n",
       "1     –¢–∞–ª—ñ–ø—Ç–µ—Ä –ê–ª“ì–∞ –î—ñ–Ω—Å—ñ–∑–¥–µ—Ä–¥—ñ –ê–ª–ª–∞–Ω—ã“£ –ø–∞—Ä—ã–∑ –±–æ–ª“ì–∞–Ω...      1   \n",
       "2     –ê—Ç—É –∫–µ—Ä–µ–∫ —Ç–∞–º—ã—Ä—ã–º–µ–Ω –∂–æ–π—ã–ª“ì–∞–Ω–¥–∞–π! https://www.y...      1   \n",
       "3     —Å–æ“ì—ã—Å –±–æ–ª—Å–∞ –±–æ–ª—Å—ã–Ω,–∂–µ–º“õ–æ—Ä –π—Ç—Ç–µ—Ä–¥—ñ “õ—É—ã–ø –∂—É—Ä—ñ–ø ”©...      1   \n",
       "4     –¢–∞–ª–∏–±—Ç–µ—Ä–¥—ñ“£ “Ø—Å—Ç—ñ–Ω–µ–Ω –±–æ–º–±–∞ —Ç–∞—Å—Ç–∞–ø –∂–æ–∫ –∫—ã–ª—ã–ø –∂—ñ–±...      1   \n",
       "...                                                 ...    ...   \n",
       "5931  –º–∞—Å–æ–Ω–¥—ã“õ “Ø–π–¥–µ–Ω —à—ã“õ“õ–∞–Ω –±“±–ª –∞–¥–∞–º–¥–∞—Ä ”©–∑–¥–µ—Ä—ñ–Ω—ñ“£ —Å—ã...      1   \n",
       "5932  –ù–µ–≥–µ —Å–µ–Ω—É—à—ñ–ª–µ—Ä–¥—ñ“£ —Å–µ–∑—ñ–º–¥–µ—Ä—ñ–Ω “õ–æ—Ä–ª–∞—É“ì–∞ –±–æ–ª–º–∞–π–¥—ã...      1   \n",
       "5933  –®—ã–Ω –º”ô–Ω—ñ–Ω–¥–µ, –∞—Ç–µ–∏—Å—Ç–µ—Ä –¥—ñ–Ω–¥–∞—Ä–ª–∞—Ä–¥—ã“£ ”©–∑–¥–µ—Ä—ñ–Ω–µ “õ–∞...      1   \n",
       "5934  –ö–∏–µ–ª—ñ –∫—ñ—Ç–∞–ø—Ç–∞ –∫—Ä–µ—Å—Ç—Ç–µ—Ä —Ç—É—Ä–∞–ª—ã –µ—à—Ç–µ“£–µ –∞–π—Ç—ã–ª–º–∞“ì–∞...      1   \n",
       "5935  ”®–ª–≥–µ–Ω—à–µ ”ô—Ä–±—ñ—Ä “õ–∞–∑–∞“õ –∞–∑–∞–º–∞—Ç—ã –∂”ô–Ω–µ –∞–∑–∞–º–∞—Ç—à–∞—Å—ã –µ–ª...      1   \n",
       "\n",
       "                                                 tokens  \n",
       "0     “õ–∞–∑–∞“õ—Å—Ç –±“±–∑ –∂–∞—Ç—ã—Ä“ì –µ—Ä—Å ”ô–º—ñ—Ä–µ –∞–±–¥“±“ì–∞–ø–ø–∞—Ä –∞—Ä–º “õ—É...  \n",
       "1     —Ç–∞–ª –∞–ª –¥ –∞–ª–ª–∞–Ω—ã“£ –ø–∞—Ä—ã–∑ –±–æ–ª“ì –∂“Ø–∑ ”©–≥—ñ—Ä–≥ “õ“±—Ä—Ç—É –∫–µ...  \n",
       "2                             –∞—Ç—É –∫–µ—Ä–µ–∫ —Ç–∞–º—ã—Ä—ã–º –∂–æ–π—ã–ª“ì   \n",
       "3             —Å–æ“ì—ã—Å –±–æ–ª—Å–∞ –±–æ–ª—Å –∂–µ–º“õ–æ—Ä –π—Ç “õ—É –∂—É—Ä ”©–ª—Ç—ñ—Ä–µ   \n",
       "4     —Ç–∞–ª–∏–± “Ø—Å—Ç –±–æ–º —Ç–∞—Å—Ç–∞–ø –∂–æ–∫ –∫—ã–ª –∂—ñ–±–µ—Ä–µ—Ç—ñ–Ω–≥–æ –±—É–ª –∞...  \n",
       "...                                                 ...  \n",
       "5931  –º–∞—Å–æ–Ω “Ø–π–¥ —à—ã“õ“õ –∞–¥–∞–º ”©–∑–¥–µ—Ä—ñ–Ω—ñ“£ —Å—ã–π–∞“õ—ã “õ–∞–ª–∞–π –∞–ª–∞...  \n",
       "5932  –Ω–µ —Å–µ–Ω—É —Å–µ–∑—ñ–º “õ–æ—Ä–ª–∞—É –±–æ–ª–º–∞–π –∞—Ç–µ–∏—Å —Å–µ–∑—ñ–º “õ–æ—Ä–ª–∞—É...  \n",
       "5933  —à—ã–Ω –º”ô–Ω –∞—Ç–µ–∏—Å –¥—ñ–Ω ”©–∑–¥–µ—Ä—ñ “õ–∞—Ä–∞“ì –¥—ñ–Ω –∫”©–±—ñ—Ä–µ–∫ –±—ñ–ª...  \n",
       "5934  –∫–∏–µ –∫—ñ—Ç–∞–ø –∫—Ä–µ—Å—Ç –µ—à—Ç–µ“£–µ –∞–π—Ç—ã–ª–º–∞“ì “õ–∞—Å–∏–µ—Ç —Å—É —à–æ–º—ã...  \n",
       "5935  ”©–ª–≥–µ–Ω—à–µ “õ–∞–∑–∞“õ –∞–∑–∞ –∂”ô –∞–∑–∞–º–∞—Ç—à–∞—Å—ã –µ–ª “õ–æ—Ä“ì–∞–π –µ—à–∫—ñ...  \n",
       "\n",
       "[5936 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df1['tokens'] = df1['text'].apply(lambda text: remove_stopwords(text))\n",
    "print('Remove Stopwords: complete')\n",
    "df1['tokens'] = df1['tokens'].apply(lambda text: clean_text(text.lower()))\n",
    "print('Clean Text: complete')\n",
    "df1['tokens'] = df1['tokens'].apply(lambda text: cleanWords(text))\n",
    "print('Clean Words: complete')\n",
    "\n",
    "df1\n",
    "#df['tokens'] = df['text'].apply(lambda text: remove_stopwords(text))\n",
    "#print('Remove Stopwords: complete')\n",
    "#df['tokens'] = df['tokens'].apply(lambda text: clean_text(text))\n",
    "#print('Clean Text: complete')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "225ce88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download comments\n",
      "53\n",
      "download replies\n",
      "1\n",
      "2\n",
      "1\n",
      "23\n",
      "1\n",
      "2\n",
      "12\n",
      "1\n",
      "7\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "8\n",
      "2\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "7\n",
      "69\n",
      "Open csv file\n",
      "Start write in csv\n",
      "Write comments in csv\n",
      "Write replies in csv\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import googleapiclient.discovery\n",
    "import csv\n",
    "import pandas as pd\n",
    "DEVELOPER_KEY = \"AIzaSyC7f4CZv7Neg84r1ilcvxXGK7eq8KJ_puk\"\n",
    "VIDEO_ID = \"ve81i_cMujk\"\n",
    "\n",
    "\n",
    "def youtube(nextPageToken=None):\n",
    "    \n",
    "    os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "\n",
    "    api_service_name = \"youtube\"\n",
    "    api_version = \"v3\"    \n",
    "\n",
    "    youtube = googleapiclient.discovery.build(\n",
    "        api_service_name, api_version, developerKey = DEVELOPER_KEY)\n",
    "\n",
    "    request = youtube.commentThreads().list(\n",
    "        part=\"id,snippet\",\n",
    "        maxResults=100,\n",
    "        pageToken=nextPageToken,\n",
    "        videoId=VIDEO_ID\n",
    "    )\n",
    "    response = request.execute()\n",
    "    return response\n",
    "\n",
    "\n",
    "def youtubechild(NextParentId, nextPageToken=None):\n",
    "    \n",
    "    os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "\n",
    "    api_service_name = \"youtube\"\n",
    "    api_version = \"v3\"\n",
    "\n",
    "    youtube = googleapiclient.discovery.build(\n",
    "        api_service_name, api_version, developerKey = DEVELOPER_KEY)\n",
    "\n",
    "    request = youtube.comments().list(\n",
    "        part=\"id,snippet\",\n",
    "        maxResults=100,\n",
    "\tpageToken=nextPageToken,\n",
    "        parentId=NextParentId\n",
    "    )\n",
    "    response = request.execute()\n",
    "    return response\n",
    "\n",
    "\n",
    "def main():\n",
    "    dataFrame = pd.DataFrame(columns=['text', 'mark'])\n",
    "    \n",
    "    print('download comments')\n",
    "    response = youtube()\n",
    "    items = response.get(\"items\")\n",
    "    nextPageToken = response.get(\"nextPageToken\") \n",
    "    i=1\n",
    "    while nextPageToken is not None:\n",
    "        print(str(i*100)) \n",
    "        response = youtube(nextPageToken)\n",
    "        nextPageToken = response.get(\"nextPageToken\")\n",
    "        items = items + response.get(\"items\")\n",
    "        i+=1\n",
    "\n",
    "    print(len(items)) \n",
    "\n",
    "    \n",
    "    print('download replies')\n",
    "    replies = []\n",
    "    for line in items: \n",
    "        if line.get(\"snippet\").get(\"totalReplyCount\") > 0: \n",
    "            print(line.get(\"snippet\").get(\"totalReplyCount\")) \n",
    "            response = youtubechild(line.get(\"snippet\").get(\"topLevelComment\").get(\"id\"))\n",
    "            replies = replies + response.get(\"items\")\n",
    "            nextPageToken = response.get(\"nextPageToken\")\n",
    "            i=1\n",
    "            while nextPageToken is not None: # –¥–æ–≥—Ä—É–∂–∞–µ–º —Ä–µ–ø–ª–∞–∏, –µ—Å–ª–∏ –µ—Å—Ç—å –µ—â—ë –ø–æ—Ä—Ü–∏–∏\n",
    "                response = youtubechild(line.get(\"snippet\").get(\"topLevelComment\").get(\"id\"), nextPageToken)\n",
    "                nextPageToken = response.get(\"nextPageToken\")\n",
    "                replies = replies + response.get(\"items\")\n",
    "                i+=1\n",
    "\n",
    "    print(len(replies)) \n",
    "\n",
    "    \n",
    "    print(\"Open csv file\")\n",
    "    with open('youtuberesults.csv', 'w', encoding=\"utf-8\") as csv_file:  \n",
    "        writer = csv.writer(csv_file, quoting=csv.QUOTE_ALL, lineterminator='\\r') \n",
    "\n",
    "        \n",
    "        row = [\n",
    "              \n",
    "            'textOriginal'\n",
    "            \n",
    "        ]\n",
    "        print(\"Start write in csv\")  \n",
    "         \n",
    "    \n",
    "        \n",
    "        print(\"Write comments in csv\")  \n",
    "        for line in items:\n",
    "            topLevelComment = line.get(\"snippet\").get(\"topLevelComment\")\n",
    "            \n",
    "            if topLevelComment.get('snippet').get('authorChannelId') is not None:\n",
    "                authorChannelId = topLevelComment.get('snippet').get('authorChannelId').get('value')\n",
    "            else:\n",
    "                authorChannelId = ''\n",
    "            row = [\n",
    "                  \n",
    "                topLevelComment.get('snippet').get('textOriginal')\n",
    "                \n",
    "            ]\n",
    "            \n",
    "\n",
    "        \n",
    "        print(\"Write replies in csv\")  \n",
    "        for line in replies:\n",
    "            \n",
    "            if line.get('snippet').get('authorChannelId') is not None:\n",
    "                authorChannelId = line.get('snippet').get('authorChannelId').get('value')\n",
    "            else:\n",
    "                authorChannelId = ''\n",
    "            row = [\n",
    "                  \n",
    "                line.get('snippet').get('textOriginal')\n",
    "                \n",
    "            ]\n",
    "            dataFrame = dataFrame.append({'text': row, 'mark': 0}, ignore_index=True)\n",
    "            dataFrame.to_csv('KZcorpYouTube-4.csv')\n",
    "            writer.writerow(row)\n",
    "        \n",
    "    print(\"done\")  \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5b14b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6397)\t0.3057792355965335\n",
      "  (0, 5582)\t0.1852607384392991\n",
      "  (0, 4393)\t0.1706882258297782\n",
      "  (0, 11319)\t0.264979475288037\n",
      "  (0, 9401)\t0.3208372131878158\n",
      "  (0, 10747)\t0.3208372131878158\n",
      "  (0, 2247)\t0.2610666446842301\n",
      "  (0, 8475)\t0.4430518093681996\n",
      "  (0, 8759)\t0.3208372131878158\n",
      "  (0, 11576)\t0.2513230807224925\n",
      "  (0, 4460)\t0.24600866709294777\n",
      "  (0, 6401)\t0.17004233924967127\n",
      "  (0, 12866)\t0.21672729854451137\n",
      "  (1, 13664)\t0.3129046330265154\n",
      "  (1, 645)\t0.22774610487181854\n",
      "  (1, 11464)\t0.3807041487252418\n",
      "  (1, 2501)\t0.30628803163151674\n",
      "  (1, 10610)\t0.2488060786762913\n",
      "  (1, 14240)\t0.28455631719990554\n",
      "  (1, 1374)\t0.2565302140587354\n",
      "  (1, 1075)\t0.2712546653474525\n",
      "  (1, 2325)\t0.1986057952079082\n",
      "  (1, 655)\t0.3807041487252418\n",
      "  (1, 10810)\t0.3486548715501297\n",
      "  (1, 13582)\t0.15254723309223645\n",
      "  :\t:\n",
      "  (4152, 12787)\t0.32829607968414576\n",
      "  (4152, 4998)\t0.32829607968414576\n",
      "  (4152, 8623)\t0.32829607968414576\n",
      "  (4152, 2761)\t0.32829607968414576\n",
      "  (4152, 12596)\t0.32829607968414576\n",
      "  (4152, 1994)\t0.32829607968414576\n",
      "  (4152, 6437)\t0.32829607968414576\n",
      "  (4152, 13424)\t0.3128880322133687\n",
      "  (4152, 3393)\t0.19968613324368306\n",
      "  (4153, 2238)\t0.41447474933737355\n",
      "  (4153, 7947)\t0.41447474933737355\n",
      "  (4153, 7537)\t0.3950220448781156\n",
      "  (4153, 7755)\t0.3617674269576914\n",
      "  (4153, 8483)\t0.2914180403730291\n",
      "  (4153, 12499)\t0.37051453562361997\n",
      "  (4153, 9603)\t0.31471089557610077\n",
      "  (4153, 6401)\t0.2196698295592995\n",
      "  (4154, 656)\t0.4333876319266265\n",
      "  (4154, 733)\t0.3874214712597814\n",
      "  (4154, 12926)\t0.3260301942848161\n",
      "  (4154, 5299)\t0.3579348734618779\n",
      "  (4154, 3958)\t0.3394877848507687\n",
      "  (4154, 603)\t0.3579348734618779\n",
      "  (4154, 729)\t0.3394877848507687\n",
      "  (4154, 1877)\t0.2627649464986486\n",
      "  (0, 12866)\t1\n",
      "  (0, 6401)\t1\n",
      "  (0, 4460)\t1\n",
      "  (0, 11576)\t1\n",
      "  (0, 8759)\t1\n",
      "  (0, 8475)\t2\n",
      "  (0, 2247)\t1\n",
      "  (0, 10747)\t1\n",
      "  (0, 9401)\t1\n",
      "  (0, 11319)\t1\n",
      "  (0, 4393)\t1\n",
      "  (0, 5582)\t1\n",
      "  (0, 6397)\t1\n",
      "  (1, 13582)\t1\n",
      "  (1, 10810)\t1\n",
      "  (1, 655)\t1\n",
      "  (1, 2325)\t1\n",
      "  (1, 1075)\t1\n",
      "  (1, 1374)\t1\n",
      "  (1, 14240)\t1\n",
      "  (1, 10610)\t1\n",
      "  (1, 2501)\t1\n",
      "  (1, 11464)\t1\n",
      "  (1, 645)\t1\n",
      "  (1, 13664)\t1\n",
      "  :\t:\n",
      "  (4152, 13424)\t1\n",
      "  (4152, 6437)\t1\n",
      "  (4152, 1994)\t1\n",
      "  (4152, 12596)\t1\n",
      "  (4152, 2761)\t1\n",
      "  (4152, 8623)\t1\n",
      "  (4152, 4998)\t1\n",
      "  (4152, 12787)\t1\n",
      "  (4152, 8185)\t1\n",
      "  (4153, 6401)\t1\n",
      "  (4153, 9603)\t1\n",
      "  (4153, 12499)\t1\n",
      "  (4153, 8483)\t1\n",
      "  (4153, 7755)\t1\n",
      "  (4153, 7537)\t1\n",
      "  (4153, 7947)\t1\n",
      "  (4153, 2238)\t1\n",
      "  (4154, 1877)\t1\n",
      "  (4154, 729)\t1\n",
      "  (4154, 603)\t1\n",
      "  (4154, 3958)\t1\n",
      "  (4154, 5299)\t1\n",
      "  (4154, 12926)\t1\n",
      "  (4154, 733)\t1\n",
      "  (4154, 656)\t1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import nltk, ssl \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.snowball import SnowballStemmer \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.model_selection import train_test_split \n",
    "phrases1 = df1['tokens'].values\n",
    "sentiments = df1['metka'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(phrases1, sentiments, test_size=.3, random_state=42)\n",
    "\n",
    "tfidfv = TfidfVectorizer()\n",
    "cv = CountVectorizer()\n",
    "\n",
    "X_train_tfidfv = tfidfv.fit_transform(X_train)\n",
    "X_test_tfidfv  = tfidfv.transform(X_test)\n",
    "\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv  = cv.transform(X_test)\n",
    "\n",
    "print(X_train_tfidfv)\n",
    "print(X_train_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1da52349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=50, max_iter=1024).fit(X_train_tfidfv, y_train)\n",
    "score = clf.score(X_test_tfidfv, y_test)\n",
    "print(f\"LogisticRegression TfidfVectorizer accuracy: {score*100:.4f}%\")\n",
    "\n",
    "clf = LogisticRegression(random_state=50, max_iter=1024).fit(X_train_cv, y_train)\n",
    "score = clf.score(X_test_cv, y_test)\n",
    "print(f\"LogisticRegression CountVectorizer accuracy: {score*100:.4f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
